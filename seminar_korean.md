![image](https://github.com/user-attachments/assets/916aca90-c548-4142-976f-238f84ee5809)

![image](https://github.com/user-attachments/assets/52dbf475-b23b-4b06-ae7d-0bfa7d85ed3d)

# ì´ì¬ì›…
- https://github.com/jamesnet214
- https://jamesnet.dev
- https://github.com/jamesnetgroup

# Ollama API Management System

## ğŸ“‘ ëª©ì°¨

- [1. Server (Minimal API)](#1-server-minimal-api)
  - [Project ìƒì„±](#project-ìƒì„±)
  - [ê°„ë‹¨í•œ API ì†ŒìŠ¤ì½”ë“œ](#ê°„ë‹¨í•œ-api-ì†ŒìŠ¤ì½”ë“œ)
  - [Ollama ê´€ë¦¬ API ì „ì²´ ì†ŒìŠ¤ì½”ë“œ](#ollama-ê´€ë¦¬-api-ì „ì²´-ì†ŒìŠ¤ì½”ë“œ)
  - [API ì—”ë“œí¬ì¸íŠ¸ë³„ í†µì‹  ë°©ì‹](#api-ì—”ë“œí¬ì¸íŠ¸ë³„-í†µì‹ -ë°©ì‹)
  - [ì£¼ìš” ëª¨ë¸](#ì£¼ìš”-ëª¨ë¸)
  - [Api Client ì „ì²´ ì†ŒìŠ¤ì½”ë“œ](#api-client-ì „ì²´-ì†ŒìŠ¤ì½”ë“œ)
  - [API Client ì •ì˜](#api-client-ì •ì˜)
  - [SignalR Client ì •ì˜](#signalr-client-ì •ì˜)
  - [API ì£¼ì†Œ ëª©ë¡](#api-ì£¼ì†Œ-ëª©ë¡)

---

## 1. Server (Minimal API)

#### Project ìƒì„±
```
dotnet new web -n MyOllamaAPI
```

#### ê°„ë‹¨í•œ API ì†ŒìŠ¤ì½”ë“œ
```csharp
var builder = WebApplication.CreateBuilder(args);
var app = builder.Build();

app.MapGet("/api/users", () =>
{
    return new[] { "James", "Vicky" };
});

app.Run();
```

#### Ollama ê´€ë¦¬ API ì „ì²´ ì†ŒìŠ¤ì½”ë“œ
```csharp
using System.Diagnostics;
using System.Text.Json;
using Microsoft.AspNetCore.SignalR;

var builder = WebApplication.CreateBuilder(args);

builder.Services.AddCors(options =>
{
    options.AddDefaultPolicy(policy => policy.AllowAnyOrigin().AllowAnyMethod().AllowAnyHeader());
});

builder.Services.AddSignalR();
builder.Services.AddHttpClient("Ollama", client =>
{
    client.BaseAddress = new Uri("http://localhost:11434/");
    client.Timeout = TimeSpan.FromMinutes(5);
});
builder.Services.AddHostedService<ModelMonitorService>();

var app = builder.Build();

app.UseCors();
app.MapHub<ModelHub>("/modelhub");

app.MapGet("/api/models", async () =>
{
    var listProcess = new Process
    {
        StartInfo = new ProcessStartInfo
        {
            FileName = "ollama",
            Arguments = "list",
            RedirectStandardOutput = true,
            UseShellExecute = false,
            CreateNoWindow = true
        }
    };
    listProcess.Start();
    var listOutput = await listProcess.StandardOutput.ReadToEndAsync();
    await listProcess.WaitForExitAsync();

    var psProcess = new Process
    {
        StartInfo = new ProcessStartInfo
        {
            FileName = "ollama",
            Arguments = "ps",
            RedirectStandardOutput = true,
            UseShellExecute = false,
            CreateNoWindow = true
        }
    };
    psProcess.Start();
    var psOutput = await psProcess.StandardOutput.ReadToEndAsync();
    await psProcess.WaitForExitAsync();

    var models = ParseOllamaModels(listOutput, psOutput);
    return Results.Ok(new { models, count = models.Count });
});

app.MapPost("/api/models/{modelName}/start", async (string modelName, IHubContext<ModelHub> hubContext) =>
{
    var process = new Process
    {
        StartInfo = new ProcessStartInfo
        {
            FileName = "ollama",
            Arguments = $"run {modelName}",
            RedirectStandardOutput = true,
            UseShellExecute = false,
            CreateNoWindow = true
        }
    };
    process.Start();
    await process.WaitForExitAsync();

    await Task.Delay(2000);
    var status = await CheckModelRunning(modelName) ? "Running" : "Error";
    await hubContext.Clients.Group("ModelUpdates").SendAsync("ModelStatusChanged", modelName, status);

    return Results.Ok(new { success = true });
});

app.MapPost("/api/models/{modelName}/stop", async (string modelName, IHubContext<ModelHub> hubContext, IHttpClientFactory httpClientFactory) =>
{
    var client = httpClientFactory.CreateClient("Ollama");
    var content = new StringContent(JsonSerializer.Serialize(new { model = modelName, keep_alive = 0 }), System.Text.Encoding.UTF8, "application/json");

    await client.PostAsync("api/generate", content);
    await Task.Delay(1000);

    var status = await CheckModelRunning(modelName) ? "Running" : "Stopped";
    await hubContext.Clients.Group("ModelUpdates").SendAsync("ModelStatusChanged", modelName, status);

    return Results.Ok(new { success = true });
});

app.MapPost("/api/chat", async (ChatRequest request, IHubContext<ModelHub> hubContext, IHttpClientFactory httpClientFactory) =>
{
    if (!await CheckModelRunning(request.Model))
    {
        await hubContext.Clients.All.SendAsync("ChatMessageReceived", $"ëª¨ë¸ {request.Model}ì„ ì‹œì‘í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤...");

        var startProcess = new Process
        {
            StartInfo = new ProcessStartInfo
            {
                FileName = "ollama",
                Arguments = $"run {request.Model}",
                RedirectStandardOutput = true,
                UseShellExecute = false,
                CreateNoWindow = true
            }
        };
        startProcess.Start();
        await startProcess.WaitForExitAsync();

        await Task.Delay(3000);

        if (!await CheckModelRunning(request.Model))
        {
            await hubContext.Clients.All.SendAsync("ChatMessageReceived", $"ëª¨ë¸ {request.Model}ì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.");
            return Results.BadRequest(new { success = false });
        }
    }

    var client = httpClientFactory.CreateClient("Ollama");
    var content = new StringContent(
        JsonSerializer.Serialize(new { model = request.Model, prompt = request.Message, stream = false }),
        System.Text.Encoding.UTF8, "application/json");

    var response = await client.PostAsync("api/generate", content);
    var responseContent = await response.Content.ReadAsStringAsync();

    if (response.IsSuccessStatusCode)
    {
        var ollamaResponse = JsonSerializer.Deserialize<OllamaResponse>(responseContent);
        var message = ollamaResponse?.response ?? "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.";
        await hubContext.Clients.All.SendAsync("ChatMessageReceived", message);
        return Results.Ok(new { success = true, response = message });
    }

    var testResponse = $"í…ŒìŠ¤íŠ¸ ì‘ë‹µ: '{request.Message}'ì— ëŒ€í•œ ë‹µë³€ì…ë‹ˆë‹¤.";
    await hubContext.Clients.All.SendAsync("ChatMessageReceived", testResponse);
    return Results.Ok(new { success = true, response = testResponse });
});

app.Run();

static List<OllamaModel> ParseOllamaModels(string listOutput, string psOutput)
{
    var runningModels = new HashSet<string>();

    foreach (var line in psOutput.Split('\n').Skip(1))
    {
        var parts = line.Trim().Split(' ', StringSplitOptions.RemoveEmptyEntries);
        if (parts.Length > 0) runningModels.Add(parts[0]);
    }

    var models = new List<OllamaModel>();
    foreach (var line in listOutput.Split('\n').Skip(1))
    {
        var parts = line.Trim().Split(' ', StringSplitOptions.RemoveEmptyEntries);
        if (parts.Length >= 4)
        {
            models.Add(new OllamaModel
            {
                Name = parts[0],
                Size = $"{parts[2]} {parts[3]}",
                LastUsed = string.Join(" ", parts.Skip(4)),
                Status = runningModels.Contains(parts[0]) ? "Running" : "Stopped"
            });
        }
    }
    return models;
}

static async Task<bool> CheckModelRunning(string modelName)
{
    var process = new Process
    {
        StartInfo = new ProcessStartInfo
        {
            FileName = "ollama",
            Arguments = "ps",
            RedirectStandardOutput = true,
            UseShellExecute = false,
            CreateNoWindow = true
        }
    };
    process.Start();
    var output = await process.StandardOutput.ReadToEndAsync();
    await process.WaitForExitAsync();
    return output.Contains(modelName);
}

public class ModelHub : Hub
{
    public override async Task OnConnectedAsync()
    {
        await Groups.AddToGroupAsync(Context.ConnectionId, "ModelUpdates");
        await base.OnConnectedAsync();
    }
}

public class ModelMonitorService : BackgroundService
{
    private readonly IHubContext<ModelHub> _hubContext;
    private readonly Dictionary<string, string> _lastStatus = new();

    public ModelMonitorService(IHubContext<ModelHub> hubContext) => _hubContext = hubContext;

    protected override async Task ExecuteAsync(CancellationToken stoppingToken)
    {
        while (!stoppingToken.IsCancellationRequested)
        {
            var currentStatus = await GetModelStatus();

            foreach (var (modelName, status) in currentStatus)
            {
                if (!_lastStatus.TryGetValue(modelName, out var prevStatus) || prevStatus != status)
                {
                    _lastStatus[modelName] = status;
                    await _hubContext.Clients.Group("ModelUpdates").SendAsync("ModelStatusChanged", modelName, status);
                }
            }

            foreach (var removed in _lastStatus.Keys.Except(currentStatus.Keys).ToList())
                _lastStatus.Remove(removed);

            await Task.Delay(3000, stoppingToken);
        }
    }

    private async Task<Dictionary<string, string>> GetModelStatus()
    {
        var result = new Dictionary<string, string>();
        var running = new HashSet<string>();

        var psProcess = new Process
        {
            StartInfo = new ProcessStartInfo
            {
                FileName = "ollama",
                Arguments = "ps",
                RedirectStandardOutput = true,
                UseShellExecute = false,
                CreateNoWindow = true
            }
        };
        psProcess.Start();
        var psOutput = await psProcess.StandardOutput.ReadToEndAsync();
        await psProcess.WaitForExitAsync();

        foreach (var line in psOutput.Split('\n').Skip(1))
        {
            var parts = line.Trim().Split(' ', StringSplitOptions.RemoveEmptyEntries);
            if (parts.Length > 0) running.Add(parts[0]);
        }

        var listProcess = new Process
        {
            StartInfo = new ProcessStartInfo
            {
                FileName = "ollama",
                Arguments = "list",
                RedirectStandardOutput = true,
                UseShellExecute = false,
                CreateNoWindow = true
            }
        };
        listProcess.Start();
        var listOutput = await listProcess.StandardOutput.ReadToEndAsync();
        await listProcess.WaitForExitAsync();

        foreach (var line in listOutput.Split('\n').Skip(1))
        {
            var parts = line.Trim().Split(' ', StringSplitOptions.RemoveEmptyEntries);
            if (parts.Length >= 1)
            {
                var modelName = parts[0];
                result[modelName] = running.Contains(modelName) ? "Running" : "Stopped";
            }
        }

        return result;
    }
}

public class OllamaModel
{
    public string Name { get; set; } = "";
    public string Size { get; set; } = "";
    public string LastUsed { get; set; } = "";
    public string Status { get; set; } = "";
}

public class ChatRequest
{
    public string Message { get; set; } = "";
    public string Model { get; set; } = "";
}

public class OllamaResponse
{
    public string response { get; set; } = "";
}
```

### API ì—”ë“œí¬ì¸íŠ¸ë³„ í†µì‹  ë°©ì‹

### 1. `GET /api/models`
- **Ollama í†µì‹ **: CMD ëª…ë ¹ì–´ 2ê°œ ì‹¤í–‰
  - `ollama list` (ì „ì²´ ëª¨ë¸ ëª©ë¡)
  - `ollama ps` (ì‹¤í–‰ì¤‘ì¸ ëª¨ë¸ ìƒíƒœ)
- **SignalR**: ì‚¬ìš© ì•ˆí•¨ (ë‹¨ìˆœ ì¡°íšŒ)

### 2. `POST /api/models/{modelName}/start`
- **Ollama í†µì‹ **: CMD ëª…ë ¹ì–´ `ollama run {modelName}` ì‹¤í–‰
- **SignalR**: ëª¨ë¸ ì‹œì‘ í›„ ìƒíƒœë¥¼ ëª¨ë“  í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ì‹¤ì‹œê°„ ë¸Œë¡œë“œìºìŠ¤íŠ¸

### 3. `POST /api/models/{modelName}/stop`
- **Ollama í†µì‹ **: HTTP API í˜¸ì¶œ (`http://localhost:11434/api/generate`)
  - JSONìœ¼ë¡œ `keep_alive: 0` ì „ì†¡í•˜ì—¬ ëª¨ë¸ ì¢…ë£Œ
- **SignalR**: ëª¨ë¸ ì¤‘ì§€ í›„ ìƒíƒœë¥¼ ëª¨ë“  í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ì‹¤ì‹œê°„ ë¸Œë¡œë“œìºìŠ¤íŠ¸

### 4. `POST /api/chat`
- **Ollama í†µì‹ **: 
  - ëª¨ë¸ ìƒíƒœ í™•ì¸: CMD `ollama ps`
  - ëª¨ë¸ ì‹œì‘ (í•„ìš”ì‹œ): CMD `ollama run {modelName}`
  - ì±„íŒ… ìš”ì²­: HTTP API (`/api/generate`)
- **SignalR**: AI ì‘ë‹µì„ ëª¨ë“  í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ì‹¤ì‹œê°„ ì „ì†¡

**í•µì‹¬**: CMD ëª…ë ¹ì–´ëŠ” ëª¨ë¸ ê´€ë¦¬ìš©, HTTP APIëŠ” ì‹¤ì œ AI í†µì‹ ìš©ìœ¼ë¡œ êµ¬ë¶„í•´ì„œ ì‚¬ìš©

#### ì£¼ìš” ëª¨ë¸
```csharp
public partial class ModelItem : ObservableObject
{
    [ObservableProperty]
    private string _name;
    [ObservableProperty]
    private string _size;
    [ObservableProperty]
    private string _lastUsed;
    [ObservableProperty]
    private string _status;
}

public class UserMessage
{
    public string Content { get; set; }
    public DateTime Timestamp { get; set; }
}

public class AIMessage
{
    public string Content { get; set; }
    public DateTime Timestamp { get; set; }
    public string ModelName { get; set; }
    public bool IsCodeBlock { get; set; }
    public string CodeLanguage { get; set; }
}
```

#### Api Client ì „ì²´ ì†ŒìŠ¤ì½”ë“œ
```
using System;
using System.Collections.Generic;
using System.Net.Http;
using System.Text;
using System.Text.Json;
using System.Threading.Tasks;

namespace OllamaHub.Support.Local.Services;

public class ApiClient<T>
{
    private readonly HttpClient _http;

    public ApiClient()
    {
        _http = new();
        _http.Timeout = TimeSpan.FromMinutes(5);
    }

    public async Task<List<T>> GetAsync(string url)
    {
        var json = await _http.GetStringAsync(url);
        var options = new JsonSerializerOptions
        {
            PropertyNameCaseInsensitive = true
        };
        var response = JsonSerializer.Deserialize<ApiResponse<List<T>>>(json, options);
        return response?.Models ?? new List<T>();
    }

    public async Task<string> PostAsync(string url)
    {
        var response = await _http.PostAsync(url, null);
        return await response.Content.ReadAsStringAsync();
    }

    public async Task<string> PostAsync(string url, object data)
    {
        var json = JsonSerializer.Serialize(data);
        var content = new StringContent(json, Encoding.UTF8, "application/json");
        var response = await _http.PostAsync(url, content);
        return await response.Content.ReadAsStringAsync();
    }

    public void Dispose()
    {
        _http?.Dispose();
    }
}

public class ApiResponse<T>
{
    public string Message { get; set; } = "";
    public int Count { get; set; }
    public T Models { get; set; } = default!;
    public bool Success { get; set; } = true;
}
```

#### API Client ì •ì˜
```csharp
private readonly ApiClient<ModelItem> _apiClient;
public MainViewModel()
{ 
    _apiClient = new();
}
```

#### SignalR Client ì •ì˜
```csharp
  _hubConnection = new HubConnectionBuilder()
      .WithUrl("https://localhost:7171/modelhub")
      .WithAutomaticReconnect()
      .Build();

  _hubConnection.On<string, string>("ModelStatusChanged", (modelName, status) =>
  {
      var model = Models.FirstOrDefault(m => m.Name == modelName);
      if (model != null)
      {
          // ë¡œì»¬ LLM ëª¨ë¸ ìƒíƒœ Received êµ¬í˜„
      }
  });

  _hubConnection.On<string>("ChatMessageReceived", (message) =>
  {
      // ê²°ê³¼ ë©”ì‹œì§€ Received êµ¬í˜„
  });

  _hubConnection.Closed += async (error) =>
  {
      await Task.Delay(new Random().Next(0, 5) * 1000);
      await _hubConnection.StartAsync();
  };

  _hubConnection.Reconnecting += (error) => Task.CompletedTask;
  _hubConnection.Reconnected += (connectionId) => Task.CompletedTask;
```

#### API ì£¼ì†Œ ëª©ë¡
- LLM ë¡œì»¬ ëª¨ë¸ ëª©ë¡: https://localhost:7171/api/models
- LLM ë¡œì»¬ ëª¨ë¸ ì‹œì‘(Run): https://localhost:7171/api/models/{model.Name}/start
- LLM ë¡œì»¬ ëª¨ë¸ ì¤‘ì§€(Stop): https://localhost:7171/api/models/{model.Name}/stop
- LLM ì±„íŒ…(ì§ˆë¬¸): https://localhost:7171/api/chat { message = Message, model = CurrentModel.Name }

------------



# OpenSilver ì„¤ì¹˜ ë°©ë²•
wasm-tools ì›Œí¬ë¡œë“œ ì„¤ì¹˜
```
dotnet workload install wasm-tools
```

ì˜¤í”ˆì‹¤ë²„ í™ˆí˜ì´ì§€
```
[http://opensilver.com](https://opensilver.net/)
```


